{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de025d24-4ea9-4aa5-ad61-6ecd3b487b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "#for dirname, _, filenames in os.walk('LUFlow/LUFlow'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362bd4da-9bc3-489a-8dd6-f7452943358a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read a selection of the data\n",
    "df1 = pd.read_csv('LUFlow/LUFlow/2022/06/2022.06.12/2022.06.12.csv')\n",
    "df2 = pd.read_csv('LUFlow/LUFlow/2022/06/2022.06.13/2022.06.13.csv')\n",
    "df3 = pd.read_csv('LUFlow/LUFlow/2022/06/2022.06.14/2022.06.14.csv')\n",
    "\n",
    "# merge into a single dataframe\n",
    "df_dataset = pd.concat([df1, df2, df3])\n",
    "df_dataset.reset_index(drop=True, inplace=True)\n",
    "len(df_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b29a3260-8d25-4913-8458-d2232190dae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1068376 entries, 0 to 1068375\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   avg_ipt        1068376 non-null  float64\n",
      " 1   bytes_in       1068376 non-null  int64  \n",
      " 2   bytes_out      1068376 non-null  int64  \n",
      " 3   dest_ip        1068376 non-null  int64  \n",
      " 4   dest_port      964168 non-null   float64\n",
      " 5   entropy        1068376 non-null  float64\n",
      " 6   num_pkts_out   1068376 non-null  int64  \n",
      " 7   num_pkts_in    1068376 non-null  int64  \n",
      " 8   proto          1068376 non-null  int64  \n",
      " 9   src_ip         1068376 non-null  int64  \n",
      " 10  src_port       964168 non-null   float64\n",
      " 11  time_end       1068376 non-null  int64  \n",
      " 12  time_start     1068376 non-null  int64  \n",
      " 13  total_entropy  1068376 non-null  float64\n",
      " 14  label          1068376 non-null  object \n",
      " 15  duration       1068376 non-null  float64\n",
      "dtypes: float64(6), int64(9), object(1)\n",
      "memory usage: 130.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34ed5dc-8d92-430b-a8e2-4628437bb83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_ipt</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>dest_ip</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_pkts_out</th>\n",
       "      <th>num_pkts_in</th>\n",
       "      <th>proto</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>time_end</th>\n",
       "      <th>time_start</th>\n",
       "      <th>total_entropy</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.068376e+06</td>\n",
       "      <td>1.068376e+06</td>\n",
       "      <td>1.068376e+06</td>\n",
       "      <td>1068376.0</td>\n",
       "      <td>964168.000000</td>\n",
       "      <td>1.068376e+06</td>\n",
       "      <td>1.068376e+06</td>\n",
       "      <td>1.068376e+06</td>\n",
       "      <td>1.068376e+06</td>\n",
       "      <td>1068376.0</td>\n",
       "      <td>964168.000000</td>\n",
       "      <td>1.068376e+06</td>\n",
       "      <td>1.068376e+06</td>\n",
       "      <td>1.068376e+06</td>\n",
       "      <td>1.068376e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.964986e+06</td>\n",
       "      <td>6.999835e+02</td>\n",
       "      <td>3.620235e+03</td>\n",
       "      <td>786.0</td>\n",
       "      <td>14856.036961</td>\n",
       "      <td>3.024693e+00</td>\n",
       "      <td>7.804426e+00</td>\n",
       "      <td>4.931449e+00</td>\n",
       "      <td>5.609870e+00</td>\n",
       "      <td>786.0</td>\n",
       "      <td>36898.051885</td>\n",
       "      <td>1.504349e+15</td>\n",
       "      <td>1.505360e+15</td>\n",
       "      <td>1.303508e+04</td>\n",
       "      <td>1.518667e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.431051e+07</td>\n",
       "      <td>3.288582e+03</td>\n",
       "      <td>8.257190e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16039.005055</td>\n",
       "      <td>2.342624e+00</td>\n",
       "      <td>2.169485e+01</td>\n",
       "      <td>1.491951e+01</td>\n",
       "      <td>1.870952e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17895.153177</td>\n",
       "      <td>4.521068e+14</td>\n",
       "      <td>4.507452e+14</td>\n",
       "      <td>6.594120e+04</td>\n",
       "      <td>5.734541e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>786.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>786.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.655076e+10</td>\n",
       "      <td>1.655089e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>786.0</td>\n",
       "      <td>5900.000000</td>\n",
       "      <td>1.020244e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>786.0</td>\n",
       "      <td>19780.000000</td>\n",
       "      <td>1.655092e+15</td>\n",
       "      <td>1.655092e+15</td>\n",
       "      <td>3.501955e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>786.0</td>\n",
       "      <td>9200.000000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>786.0</td>\n",
       "      <td>45332.000000</td>\n",
       "      <td>1.655163e+15</td>\n",
       "      <td>1.655163e+15</td>\n",
       "      <td>3.238136e+02</td>\n",
       "      <td>1.960000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.571429e+01</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>2.904000e+03</td>\n",
       "      <td>786.0</td>\n",
       "      <td>9300.000000</td>\n",
       "      <td>5.021325e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>786.0</td>\n",
       "      <td>47613.000000</td>\n",
       "      <td>1.655182e+15</td>\n",
       "      <td>1.655182e+15</td>\n",
       "      <td>2.067165e+04</td>\n",
       "      <td>2.278970e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.294967e+09</td>\n",
       "      <td>6.548300e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>786.0</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>1.342394e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>786.0</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>1.655251e+15</td>\n",
       "      <td>1.655251e+15</td>\n",
       "      <td>3.979174e+06</td>\n",
       "      <td>4.102360e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_ipt      bytes_in     bytes_out    dest_ip      dest_port  \\\n",
       "count  1.068376e+06  1.068376e+06  1.068376e+06  1068376.0  964168.000000   \n",
       "mean   4.964986e+06  6.999835e+02  3.620235e+03      786.0   14856.036961   \n",
       "std    8.431051e+07  3.288582e+03  8.257190e+03        0.0   16039.005055   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00      786.0       1.000000   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00      786.0    5900.000000   \n",
       "50%    0.000000e+00  0.000000e+00  4.300000e+01      786.0    9200.000000   \n",
       "75%    3.571429e+01  3.400000e+01  2.904000e+03      786.0    9300.000000   \n",
       "max    4.294967e+09  6.548300e+04  6.553500e+04      786.0   65535.000000   \n",
       "\n",
       "            entropy  num_pkts_out   num_pkts_in         proto     src_ip  \\\n",
       "count  1.068376e+06  1.068376e+06  1.068376e+06  1.068376e+06  1068376.0   \n",
       "mean   3.024693e+00  7.804426e+00  4.931449e+00  5.609870e+00      786.0   \n",
       "std    2.342624e+00  2.169485e+01  1.491951e+01  1.870952e+00        0.0   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00      786.0   \n",
       "25%    1.020244e+00  1.000000e+00  0.000000e+00  6.000000e+00      786.0   \n",
       "50%    3.000000e+00  3.000000e+00  1.000000e+00  6.000000e+00      786.0   \n",
       "75%    5.021325e+00  7.000000e+00  5.000000e+00  6.000000e+00      786.0   \n",
       "max    1.342394e+02  2.550000e+02  2.550000e+02  4.700000e+01      786.0   \n",
       "\n",
       "            src_port      time_end    time_start  total_entropy      duration  \n",
       "count  964168.000000  1.068376e+06  1.068376e+06   1.068376e+06  1.068376e+06  \n",
       "mean    36898.051885  1.504349e+15  1.505360e+15   1.303508e+04  1.518667e+00  \n",
       "std     17895.153177  4.521068e+14  4.507452e+14   6.594120e+04  5.734541e+00  \n",
       "min        11.000000  1.655076e+10  1.655089e+10   0.000000e+00  0.000000e+00  \n",
       "25%     19780.000000  1.655092e+15  1.655092e+15   3.501955e+01  0.000000e+00  \n",
       "50%     45332.000000  1.655163e+15  1.655163e+15   3.238136e+02  1.960000e-04  \n",
       "75%     47613.000000  1.655182e+15  1.655182e+15   2.067165e+04  2.278970e-01  \n",
       "max     65535.000000  1.655251e+15  1.655251e+15   3.979174e+06  4.102360e+01  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b00ff7-9d82-4ddb-b794-1a212e9a2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace +ve and -ve infinity with NaN\n",
    "df_dataset.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86700c35-a75d-4038-bac4-aeb46209aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "df_dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e7d6d59-c7d4-4d47-9b97-178bf34be560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4284\n"
     ]
    }
   ],
   "source": [
    "print(df_dataset.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d97534f-2d83-48cb-8127-10e75886088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d562f330-4c8f-4cc0-9838-26a5e220861f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_dataset.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb3ba830-c50f-496d-9610-03523cacfa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dataset.drop(columns = ['label'], axis = 1)\n",
    "Y = df_dataset['label']\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.astype('int64')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state = 50)\n",
    "\n",
    "# Convert all columns to numeric types\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63662368-b527-456d-8d85-4eb28a191989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "300fb475-bf1d-42a9-bd20-8a0dc011d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "\n",
    "class TrafficNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(TrafficNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92168a40-c48b-420c-a686-a6a40587909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 15  # Adjust based on your dataset\n",
    "hidden_size = 64\n",
    "num_classes = 3 \n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7faa4d97-2d74-482f-97ab-2fcf24b6c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.tensor(X_train.values, dtype=torch.float32), torch.tensor(y_train, dtype=torch.int64))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test.values, dtype=torch.float32), torch.tensor(y_test, dtype=torch.int64))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4fe6324-44be-4ade-b38e-a9d7e5f7cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = TrafficNet(input_size, hidden_size, num_classes)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce430e54-bdd0-4166-ba9e-3678de615d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: -50139.0898\n",
      "Epoch [2/5], Loss: -172441.9062\n",
      "Epoch [3/5], Loss: -421437.7188\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.to(\"cuda\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        features = features.to(\"cuda\")\n",
    "        labels = labels.to(\"cuda\")\n",
    "        # Forward pass\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8512ed-4d29-48c4-a2bb-4018e270ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        print(f'{method.__name__}: {(te - ts) * 1000} ms')\n",
    "        return result\n",
    "    return timed\n",
    "\n",
    "@timeit\n",
    "def get_predictions(model, dataloader):\n",
    "    model = model.to(\"cuda\")\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            outputs = model(inputs)\n",
    "            # Get the index of the maximum value\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            # Append the predictions and labels to the respective lists\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "    # Return the lists of predictions and labels\n",
    "    all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "    all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad992dc-ac64-436b-abc6-6c2927c26727",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list, y_true_list = get_predictions(model, train_loader)\n",
    "y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db15488-1a0c-4dae-b92d-0da6b5532596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_true_list, y_pred_list)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot(ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2f901-df4d-4a8a-9574-f25d4c40f7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4c6b3-061a-4a0d-8f4c-99094a659a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
